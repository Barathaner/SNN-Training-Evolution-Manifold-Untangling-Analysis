import torch
from collections import defaultdict
import h5py
import numpy as np
from pathlib import Path
from typing import Dict, Optional, List
from torch.utils.data import DataLoader

class ActivityMonitor:
    def __init__(self, model):
        """
        Initialisiert den ActivityMonitor mit leeren Buffern f√ºr Spike-Aktivit√§ten.
        
        Args:
            model: Das PyTorch-Modell, das √ºberwacht werden soll
        """
        self.model = model
        # Dictionary: layer_name -> Liste von Spike-Tensoren (ein Tensor pro Zeitschritt)
        self.spike_buffer = defaultdict(list)
        # Dictionary: layer_name -> Liste von Input-Tensoren (optional, f√ºr Debugging)
        self.input_buffer = defaultdict(list)
        # Speichert die Layer-Namen f√ºr jeden registrierten Hook
        self.layer_names = {}
        # Hooks am gesamten Modell (werden beim enable_monitoring registriert)
        self.model_hooks = []
        # Hooks an einzelnen Layern
        self.layer_hooks = []
        # Flag, um zu wissen, ob ein Forward-Pass gerade l√§uft
        self.forward_pass_active = False
        # Aktuelles Label f√ºr den laufenden Forward-Pass
        self.current_labels = None
        # Metadaten pro Sample im aktuellen Batch
        # Format: {'sample_0': {'speaker': 5, 'original_sample_id': 123, ...}, ...}
        self.batch_metadata = {}
    
    def _model_pre_forward_hook(self, module, input):
        """
        Wird VOR dem Forward-Pass des GESAMTEN Modells aufgerufen.
        Wird genau EINMAL pro Forward-Pass aufgerufen (nicht pro Zeitschritt!).
        Hier l√∂schen wir den Buffer, um f√ºr einen neuen Forward-Pass bereit zu sein.
        
        Das aktuelle Label kann √ºber self.current_labels abgerufen werden,
        wenn es vorher mit set_current_labels() gesetzt wurde.
        """
        self.clear_buffer()
        self.forward_pass_active = True
        # self.current_labels ist hier verf√ºgbar, wenn es vorher gesetzt wurde
    
    def _model_forward_hook(self, module, input, output):
        """
        Wird NACH dem Forward-Pass des GESAMTEN Modells aufgerufen.
        Verwendet register_forward_hook (wird nach dem Forward-Pass aufgerufen).
        Wird genau EINMAL pro Forward-Pass aufgerufen, NACH allen Zeitschritten.
        Hier wissen wir, dass alle Zeitschritte durchgelaufen sind.
        """
        self.forward_pass_active = False
    
    def pre_forward_hook(self, module, input):
        """
        Wird VOR jedem Forward-Pass eines einzelnen Moduls aufgerufen.
        Wird bei jedem Zeitschritt f√ºr jeden Layer aufgerufen.
        """
        # Optional: Input f√ºr Debugging speichern
        # layer_name = self.layer_names.get(id(module), module.__class__.__name__)
        # self.input_buffer[layer_name].append(input[0].detach().cpu() if isinstance(input, tuple) else input.detach().cpu())
        pass
    
    def forward_hook(self, module, input, output):
        """
        Wird NACH jedem Forward-Pass eines Moduls aufgerufen.
        Hier sammeln wir die Spikes pro Layer √ºber alle Zeitschritte.
        
        Args:
            module: Das Modul, das den Hook ausgel√∂st hat
            input: Input zum Modul
            output: Output vom Modul (bei LIF-Layern: (spk, mem) Tupel)
        """
        # Hole den Layer-Namen (wird beim Registrieren gesetzt)
        layer_name = self.layer_names.get(id(module), module.__class__.__name__)
        
        # Bei snntorch LIF-Layern ist output ein Tupel (spk, mem)
        if isinstance(output, tuple) and len(output) >= 1:
            spikes = output[0]  # Erste Komponente sind die Spikes
        else:
            # Falls kein Tupel, nehmen wir den Output direkt
            spikes = output
        
        # Spikes detachen und auf CPU kopieren (wichtig f√ºr Speicher!)
        # Shape: [Batch, Features] pro Zeitschritt
        spikes_detached = spikes.detach().cpu()
        
        # F√ºge die Spikes f√ºr diesen Zeitschritt zur Liste hinzu
        self.spike_buffer[layer_name].append(spikes_detached)
    
    def full_backward_hook(self, module, grad_input, grad_output):
        """
        Wird w√§hrend des Backward-Passes aufgerufen.
        """
        # Optional: Gradienten f√ºr Debugging speichern
        pass
    
    def enable_monitoring(self, lif_layer_names=None, verbose=True):
        """
        Aktiviert das Monitoring f√ºr das gesamte Modell.
        Registriert Hooks am Modell und an allen Layern, um Spikes zu sammeln.
        
        Args:
            lif_layer_names: Optional, Liste von Layer-Namen, die √ºberwacht werden sollen.
                            Wenn None, werden alle Leaf-Module √ºberwacht.
            verbose: Wenn True, werden registrierte Layer ausgegeben
        """
        # 1. Hooks am gesamten Modell (um zu erkennen, wann Forward-Pass beginnt/endet)
        pre_hook = self.model.register_forward_pre_hook(self._model_pre_forward_hook)
        forward_hook = self.model.register_forward_hook(self._model_forward_hook)
        self.model_hooks.extend([pre_hook, forward_hook])
        
        # 2. Hooks an einzelnen Layern (um Spikes zu sammeln)
        if lif_layer_names is None:
            # Wenn keine Layer-Namen angegeben, √ºberwache alle Leaf-Module
            lif_layer_names = []
        
        for name, module in self.model.named_modules():
            if len(list(module.children())) == 0:  # Nur Leaf-Module (keine Container)
                # Registriere Layer-Namen
                self.layer_names[id(module)] = name
                
                # Registriere Hooks f√ºr diesen Layer
                pre_hook = module.register_forward_pre_hook(self.pre_forward_hook)
                forward_hook = module.register_forward_hook(self.forward_hook)
                backward_hook = module.register_full_backward_hook(self.full_backward_hook)
                self.layer_hooks.extend([pre_hook, forward_hook, backward_hook])
                
                if verbose:
                    if name in lif_layer_names:
                        print(f"‚úÖ Registered hook for LIF-Layer: {name}")
                    else:
                        print(f"Registered hook for {name}")
            else:
                if verbose:
                    print(f"Skipping {name} because it has children")
    
    def disable_monitoring(self):
        """
        Deaktiviert das Monitoring und entfernt alle Hooks.
        """
        # Entferne Hooks am Modell
        for hook in self.model_hooks:
            hook.remove()
        self.model_hooks.clear()
        
        # Entferne Hooks an einzelnen Layern
        for hook in self.layer_hooks:
            hook.remove()
        self.layer_hooks.clear()
        
        self.forward_pass_active = False
    
    def set_current_labels(self, labels):
        """
        Setzt die Labels f√ºr den n√§chsten Forward-Pass.
        Diese Labels sind dann im _model_pre_forward_hook √ºber self.current_labels verf√ºgbar.
        
        Args:
            labels: Tensor oder Liste von Labels f√ºr den aktuellen Batch
        """
        if isinstance(labels, torch.Tensor):
            self.current_labels = labels.detach().cpu()
        else:
            self.current_labels = labels
    
    def get_current_labels(self):
        """
        Gibt die Labels des aktuellen Forward-Passes zur√ºck.
        
        Returns:
            Labels des aktuellen Forward-Passes oder None
        """
        return self.current_labels
    
    def set_batch_metadata(self, metadata: Dict[str, np.ndarray]):
        """
        Setzt Metadaten f√ºr den aktuellen Batch.
        Die Metadaten werden pro Sample im Batch gespeichert.
        
        Args:
            metadata: Dictionary mit Arrays f√ºr jeden Metadaten-Typ.
                     Keys sollten z.B. 'speakers', 'original_sample_ids' sein.
                     Die Arrays m√ºssen die gleiche L√§nge haben (Batch-Gr√∂√üe).
        
        Beispiel:
            metadata = {
                'speakers': np.array([5, 3, 7, ...]),
                'original_sample_ids': np.array([123, 456, 789, ...])
            }
            monitor.set_batch_metadata(metadata)
        """
        # Konvertiere zu Dictionary pro Sample
        self.batch_metadata = {}
        
        # Bestimme Batch-Gr√∂√üe aus den ersten Array
        if not metadata:
            return
        
        first_key = list(metadata.keys())[0]
        batch_size = len(metadata[first_key])
        
        # Erstelle Dictionary f√ºr jeden Sample im Batch
        for i in range(batch_size):
            sample_metadata = {}
            for key, values in metadata.items():
                if isinstance(values, (np.ndarray, list, torch.Tensor)):
                    if isinstance(values, torch.Tensor):
                        sample_metadata[key] = values[i].item() if values[i].numel() == 1 else values[i].cpu().numpy()
                    else:
                        sample_metadata[key] = values[i].item() if np.isscalar(values[i]) else values[i]
                else:
                    sample_metadata[key] = values
            self.batch_metadata[f'sample_{i}'] = sample_metadata
    
    def get_batch_metadata(self) -> Dict:
        """
        Gibt die Metadaten des aktuellen Batches zur√ºck.
        
        Returns:
            Dictionary mit Metadaten pro Sample: {'sample_0': {...}, 'sample_1': {...}, ...}
        """
        return self.batch_metadata
    
    def clear_buffer(self):
        """
        L√∂scht alle gesammelten Spike-Daten.
        Sollte vor jedem neuen Forward-Pass aufgerufen werden.
        """
        self.spike_buffer.clear()
        self.input_buffer.clear()
        # Labels werden nicht automatisch gel√∂scht, damit sie nach dem Forward-Pass verf√ºgbar sind
        # Metadaten werden auch nicht automatisch gel√∂scht
    
    def get_spikes(self, layer_name=None):
        """
        Gibt die gesammelten Spikes zur√ºck.
        
        Args:
            layer_name: Optional, spezifischer Layer-Name. Wenn None, werden alle Layer zur√ºckgegeben.
        
        Returns:
            Dictionary: {layer_name: Tensor} mit Shape [T, Batch, Features]
                        oder einzelner Tensor wenn layer_name angegeben
        """
        result = {}
        
        for name, spike_list in self.spike_buffer.items():
            if layer_name is None or name == layer_name:
                if spike_list:
                    # Stack √ºber Zeitschritte: [T, Batch, Features]
                    # spike_list ist eine Liste von [Batch, Features] Tensoren
                    stacked = torch.stack(spike_list, dim=0)  # [T, Batch, Features]
                    result[name] = stacked
        
        if layer_name is not None:
            return result.get(layer_name, None)
        return result
    
    def get_spikes_bt(self, layer_name=None):
        """
        Gibt die gesammelten Spikes zur√ºck, transponiert zu [Batch, T, Features].
        
        Args:
            layer_name: Optional, spezifischer Layer-Name. Wenn None, werden alle Layer zur√ºckgegeben.
        
        Returns:
            Dictionary: {layer_name: Tensor} mit Shape [Batch, T, Features]
                        oder einzelner Tensor wenn layer_name angegeben
        """
        spikes_tb = self.get_spikes(layer_name)
        
        if isinstance(spikes_tb, dict):
            return {name: tensor.permute(1, 0, 2) for name, tensor in spikes_tb.items()}
        elif spikes_tb is not None:
            return spikes_tb.permute(1, 0, 2)
        return spikes_tb
    
    def _convert_spikes_to_tonic_format(self, spikes: np.ndarray) -> Dict[int, np.ndarray]:
        """
        Konvertiert Spikes von [Batch, T, Features] in Tonic-Format (t, x, p) pro Sample.
        
        Args:
            spikes: Spikes als numpy Array [Batch, T, Features]
        
        Returns:
            Dictionary: {sample_idx: events_array} wobei events_array Shape [N_events, 3] hat
                       mit Spalten (t, x, p)
        """
        batch_size, T, num_features = spikes.shape
        events_per_sample = {}
        
        for sample_idx in range(batch_size):
            # Hole Spikes f√ºr dieses Sample: [T, Features]
            sample_spikes = spikes[sample_idx]
            
            # Finde alle Spikes (wo spike == 1)
            spike_indices = np.where(sample_spikes == 1)
            
            # Erstelle Events im Format (t, x, p)
            # t = Zeitschritt, x = Feature-Index, p = Polarity (immer 1)
            events = np.column_stack([
                spike_indices[0],  # t (Zeitschritt)
                spike_indices[1],  # x (Feature/Neuron-Index)
                np.ones(len(spike_indices[0]), dtype=np.uint8)  # p (Polarity, immer 1)
            ])
            
            # Konvertiere zu strukturiertem Array (wie in Tonic)
            dtype = np.dtype([('t', 'uint64'), ('x', 'uint16'), ('p', 'uint8')])
            events_structured = np.empty(len(events), dtype=dtype)
            events_structured['t'] = events[:, 0].astype(np.uint64)
            events_structured['x'] = events[:, 1].astype(np.uint16)
            events_structured['p'] = events[:, 2].astype(np.uint8)
            
            events_per_sample[sample_idx] = events_structured
        
        return events_per_sample
    
    def save_as_h5(self, 
                   layer_name: str,
                   save_dir: str,
                   filename: Optional[str] = None,
                   epoch: Optional[int] = None,
                   include_metadata: bool = True) -> str:
        """
        Speichert die Spikes eines Layers als HDF5-Datei im Tonic-Format (t, x, p).
        
        Das Format entspricht dem Spiking Heidelberg Digits Datensatz:
        - t: Zeit (Zeitschritt)
        - x: Neuron/Feature-Index
        - p: Polarity (hier immer 1, da bin√§re Spikes)
        
        Args:
            layer_name: Name des Layers (z.B. 'lif1')
            save_dir: Verzeichnis zum Speichern (z.B. 'data/activity_logs')
            filename: Optional, custom Dateiname. Wenn None, wird automatisch generiert.
            epoch: Optional, Epoch-Nummer f√ºr automatischen Dateinamen
            include_metadata: Wenn True, werden Metadaten und Labels mitgespeichert
        
        Returns:
            Pfad zur gespeicherten Datei
        
        Beispiel:
            # Automatischer Dateiname: epoch_001_lif1_spk_events.h5
            path = monitor.save_as_h5('lif1', 'data/activity_logs', epoch=1)
            
            # Custom Dateiname
            path = monitor.save_as_h5('lif1', 'data/activity_logs', filename='my_spikes.h5')
        """
        # Hole Spikes f√ºr diesen Layer
        spikes = self.get_spikes_bt(layer_name=layer_name)
        
        if spikes is None:
            raise ValueError(f"Keine Spikes f√ºr Layer '{layer_name}' gefunden")
        
        # Konvertiere zu numpy
        if isinstance(spikes, torch.Tensor):
            spikes_np = spikes.numpy()
        else:
            spikes_np = spikes
        
        # Konvertiere zu Tonic-Format (t, x, p) pro Sample
        events_per_sample = self._convert_spikes_to_tonic_format(spikes_np)
        
        # Erstelle Verzeichnis
        save_path = Path(save_dir)
        save_path.mkdir(parents=True, exist_ok=True)
        
        # Generiere Dateinamen
        if filename is None:
            epoch_str = f"epoch_{epoch:03d}_" if epoch is not None else ""
            filename = f"{epoch_str}{layer_name}_spk_events.h5"
        
        filepath = save_path / filename
        
        # Speichere als HDF5 im Tonic-Format
        with h5py.File(filepath, 'w') as f:
            # Speichere Events f√ºr jeden Sample im Batch
            events_group = f.create_group('events')
            
            for sample_idx, events in events_per_sample.items():
                # Erstelle Dataset f√ºr diesen Sample
                sample_key = f'sample_{sample_idx}'
                events_dataset = events_group.create_dataset(
                    sample_key,
                    data=events,
                    compression='gzip'
                )
                events_dataset.attrs['num_events'] = len(events)
                events_dataset.attrs['time_range'] = (events['t'].min(), events['t'].max()) if len(events) > 0 else (0, 0)
                events_dataset.attrs['num_features'] = spikes_np.shape[2]
            
            # Layer-Informationen
            f.attrs['layer_name'] = layer_name
            f.attrs['batch_size'] = spikes_np.shape[0]
            f.attrs['time_steps'] = spikes_np.shape[1]
            f.attrs['num_features'] = spikes_np.shape[2]
            f.attrs['format'] = 'tonic_events'  # (t, x, p)
            
            # Metadaten speichern, wenn vorhanden
            if include_metadata and self.batch_metadata:
                metadata_group = f.create_group('metadata')
                for sample_key, sample_meta in self.batch_metadata.items():
                    sample_group = metadata_group.create_group(sample_key)
                    for key, value in sample_meta.items():
                        if isinstance(value, (int, float, np.number)):
                            sample_group.attrs[key] = value
                        elif isinstance(value, (np.ndarray, list)):
                            sample_group.create_dataset(key, data=np.array(value))
                        else:
                            sample_group.attrs[key] = str(value)
            
            # Labels speichern, wenn vorhanden
            if include_metadata and self.current_labels is not None:
                labels_np = self.current_labels.numpy() if isinstance(self.current_labels, torch.Tensor) else np.array(self.current_labels)
                f.create_dataset('labels', data=labels_np, compression='gzip')
                f['labels'].attrs['description'] = 'Ground truth labels for each sample in the batch'
        
        return str(filepath)
    
    def monitor_and_save_samples(self,
                                 dataloader: DataLoader,
                                 num_samples: int,
                                 layer_names: List[str],
                                 save_dir: str,
                                 epoch: Optional[int] = None,
                                 device: torch.device = torch.device('cpu'),
                                 verbose: bool = True) -> Dict[str, str]:
        """
        √úberwacht und speichert Spikes f√ºr eine bestimmte Anzahl von Samples.
        Verwendet immer die gleichen Samples (die ersten N) f√ºr Vergleichbarkeit.
        Sammelt Spikes √ºber alle Batches und speichert am Ende.
        
        Args:
            dataloader: DataLoader f√ºr die Daten
            num_samples: Anzahl der Samples, die √ºberwacht werden sollen
            layer_names: Liste der Layer-Namen, die √ºberwacht werden sollen
            save_dir: Verzeichnis zum Speichern der HDF5-Dateien
            epoch: Optional, Epoch-Nummer f√ºr Dateinamen
            device: Device f√ºr die Berechnung
            verbose: Wenn True, werden Fortschrittsmeldungen ausgegeben
        
        Returns:
            Dictionary mit gespeicherten Dateipfaden: {layer_name: filepath}
        
        Beispiel:
            filepaths = monitor.monitor_and_save_samples(
                dataloader=test_dataloader,
                num_samples=64,
                layer_names=['lif0', 'lif1', 'lif2', 'lif3'],
                save_dir='data/activity_logs',
                epoch=1
            )
        """
        # Import hier, um zirkul√§re Imports zu vermeiden
        from manifolduntanglinganalysis.preprocessing.metadata_extractor import extract_batch_metadata
        
        # Berechne, wie viele Batches ben√∂tigt werden
        batch_size = dataloader.batch_size
        num_batches_needed = (num_samples + batch_size - 1) // batch_size  # Aufrunden
        
        if verbose:
            print(f"üìä √úberwache {num_samples} Samples ({num_batches_needed} Batches)...")
        
        # Akkumuliere Spikes und Metadaten √ºber alle Batches
        all_spikes_accumulated = {layer: [] for layer in layer_names}
        all_metadata_accumulated = []
        all_labels_accumulated = []
        
        # Iteriere √ºber Batches
        samples_collected = 0
        batch_idx = 0
        
        for events, labels in dataloader:
            if samples_collected >= num_samples:
                break
            
            # Berechne, wie viele Samples aus diesem Batch wir nehmen
            samples_in_batch = min(batch_size, num_samples - samples_collected)
            
            # Events vorbereiten
            if events.ndim == 4:
                events = events.squeeze(2)
            events = events.to(device).float()
            labels = labels.to(device)
            
            # Nimm nur die ben√∂tigten Samples aus dem Batch
            events = events[:samples_in_batch]
            labels = labels[:samples_in_batch]
            
            # Metadaten extrahieren
            batch_metadata_dict = {}
            try:
                batch_metadata = extract_batch_metadata(dataloader, batch_idx=batch_idx)
                # Nimm nur die ben√∂tigten Samples aus den Metadaten
                for key in batch_metadata:
                    batch_metadata[key] = batch_metadata[key][:samples_in_batch]
                batch_metadata_dict = batch_metadata
            except Exception as e:
                if verbose:
                    print(f"‚ö†Ô∏è Warnung: Metadaten konnten nicht extrahiert werden: {e}")
            
            # Labels setzen
            self.set_current_labels(labels)
            
            # Forward-Pass (Spikes werden automatisch gesammelt)
            with torch.no_grad():
                _ = self.model(events)
            
            # Hole Spikes f√ºr diesen Batch und akkumuliere sie
            batch_spikes = self.get_spikes_bt()
            for layer_name in layer_names:
                if layer_name in batch_spikes:
                    # Konvertiere zu numpy und f√ºge hinzu
                    spikes_np = batch_spikes[layer_name].numpy() if isinstance(batch_spikes[layer_name], torch.Tensor) else batch_spikes[layer_name]
                    all_spikes_accumulated[layer_name].append(spikes_np)
            
            # Akkumuliere Metadaten und Labels
            for i in range(samples_in_batch):
                sample_meta = {}
                for key, values in batch_metadata_dict.items():
                    sample_meta[key] = values[i] if isinstance(values, np.ndarray) else values
                all_metadata_accumulated.append(sample_meta)
            
            labels_np = labels.cpu().numpy() if isinstance(labels, torch.Tensor) else np.array(labels)
            all_labels_accumulated.append(labels_np)
            
            samples_collected += samples_in_batch
            batch_idx += 1
            
            if verbose:
                print(f"   ‚úÖ {samples_collected}/{num_samples} Samples gesammelt")
        
        # Kombiniere alle gesammelten Spikes
        combined_spikes = {}
        for layer_name in layer_names:
            if all_spikes_accumulated[layer_name]:
                # Konkateniere √ºber Batch-Dimension: [B1, T, F] + [B2, T, F] -> [B1+B2, T, F]
                combined_spikes[layer_name] = np.concatenate(all_spikes_accumulated[layer_name], axis=0)
        
        # Kombiniere Labels
        combined_labels = np.concatenate(all_labels_accumulated, axis=0) if all_labels_accumulated else None
        
        # Setze kombinierte Metadaten
        if all_metadata_accumulated:
            # Konvertiere zu Dictionary-Format f√ºr set_batch_metadata
            combined_metadata = {}
            for key in all_metadata_accumulated[0].keys():
                combined_metadata[key] = np.array([meta[key] for meta in all_metadata_accumulated])
            self.set_batch_metadata(combined_metadata)
        
        # Setze kombinierte Labels
        if combined_labels is not None:
            self.set_current_labels(torch.from_numpy(combined_labels))
        
        # Speichere Spikes f√ºr jeden Layer (mit allen Samples)
        saved_filepaths = {}
        for layer_name in layer_names:
            if layer_name in combined_spikes:
                # Tempor√§r Spikes setzen
                original_buffer = self.spike_buffer.copy()
                # Konvertiere zur√ºck zu Liste-Format f√ºr save_as_h5
                # save_as_h5 erwartet spikes im Buffer, also m√ºssen wir sie tempor√§r setzen
                # Aber eigentlich sollten wir save_as_h5 so anpassen, dass es direkt numpy arrays akzeptiert
                # F√ºr jetzt: Speichere direkt mit den kombinierten Spikes
                try:
                    # Tempor√§rer Workaround: Setze Spikes direkt
                    self.spike_buffer[layer_name] = [torch.from_numpy(combined_spikes[layer_name][:, t, :]) for t in range(combined_spikes[layer_name].shape[1])]
                    
                    filepath = self.save_as_h5(
                        layer_name=layer_name,
                        save_dir=save_dir,
                        epoch=epoch,
                        include_metadata=True
                    )
                    saved_filepaths[layer_name] = filepath
                    
                    # Stelle Buffer wieder her
                    self.spike_buffer = original_buffer
                except Exception as e:
                    if verbose:
                        print(f"‚ö†Ô∏è Fehler beim Speichern von {layer_name}: {e}")
        
        if verbose:
            print(f"‚úÖ Monitoring abgeschlossen: {samples_collected} Samples f√ºr {len(layer_names)} Layer gespeichert")
        
        return saved_filepaths
        